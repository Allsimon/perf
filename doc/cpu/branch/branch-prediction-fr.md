# üîÆ Pr√©diction de branches

Nous avons vu dans l'article pr√©c√©dent que les branches peuvent avoir un co√ªt √©lev√© en termes de performance.
Nous avons aussi vu qu'il y avait des techniques pour pouvoir √©viter d'√©crire ces branches.
Ces techniques ont cependant un co√ªt tr√®s √©lev√© en termes de complexit√© (de lecture).

Les CPUs modernes ont plusieurs techniques non intrusives pour r√©duire le co√ªt des branches.
La plupart des d√©veloppeurs peuvent simplement les ignorer et r√©cup√©rer quand m√™me une partie des b√©n√©fices.

## Pipelines

On peut imaginer un ordinateur comme une machine tr√®s simple qui suit une s√©quence d'instruction et les ex√©cute une par une, comme on le ferait pour une recette de cuisine.

Les plus vieux ordinateurs faisaient en effet cela, ils r√©cup√©raient la commande en m√©moire, la d√©codaient, l'ex√©cutaient, enregistraient le r√©sultat, r√©cup√©raient la prochaine commande et r√©p√©taient jusqu'√† ce qu'il n'y en n'ait plus ou que quelqu'un retire la prise.

M√™me si la commande C+1 n'avait pas besoin des r√©sultats de la commande, le CPU attendait patiemment que C finisse pour ex√©cuter C+1.

Par exemple, pour une fonction tr√®s simple :
```java
int doSomething(int a) {
    a+= 1;
    a+= 2;
    a+= 3;
    a+= 4;
    return a;
}
```

En simplifiant beaucoup, on peut consid√©rer que l'ex√©cution ressemblait √† cela : (Fetch, Decode, Execute, Save)

|        | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| a+= 1; | F | D | E | S |   |   |   |   |   |    |    |    |    |    |    |    |
| a+= 2; |   |   |   |   | F | D | E | S |   |    |    |    |    |    |    |    |
| a+= 3; |   |   |   |   |   |   |   |   | F | D  | E  | S  |    |    |    |    |
| a+= 4; |   |   |   |   |   |   |   |   |   |    |    |    | F  | D  | E  | S  |

Les CPUs r√©cents utilisent souvent des "Instruction Pipelines" afin d'optimiser cela.
Ces pipelines permettent par exemple d'effectuer des t√¢ches en parall√®les automatiquement.

L'ex√©cution peut donc s'effectuer de cette mani√®re, sans changer le r√©sultat final :

|        | 1 | 2 | 3 | 4 | 5 | 6 | 7 |
|--------|---|---|---|---|---|---|---|
| a+= 1; | F | D | E | S |   |   |   |
| a+= 2; |   | F | D | E | S |   |   |
| a+= 3; |   |   | F | D | E | S |   |
| a+= 4; |   |   |   | F | D | E | S |

En supposant que les temps F, D, E et S sont √©quivalents : on aurait rendu le programme ~2.2 (16/7) fois plus rapide !

Si une branche conditionnelle est pr√©sente, alors on peut l'imaginer comme un train devant son aiguillage.
![Trolley](trolley.jpg "Example de branche")

Le CPU ne peut pas savoir avec certitude quelle sera la prochaine t√¢che √† effectuer.

Par exemple, en reprenant le m√™me programme, mais en ajoutant une condition :
```java
int doSomething(int a) {
    a+= 1;
    a+= 2;
    if (a < 100) {
      a+= 3;
    }
    a+= 4;
    return a;
}
```

L'ex√©cution ressemblerait √† √ßa, si la branche est prise :

|              | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |
|--------------|---|---|---|---|---|---|---|---|---|----|----|
| a+= 1;       | F | D | E | S |   |   |   |   |   |    |    |
| a+= 2;       |   | F | D | E | S |   |   |   |   |    |    |
| if (a < 100) |   |   | F | D | E | S |   |   |   |    |    |
| a+= 3;       |   |   |   |   |   |   | F | D | E | S  |    |
| a+= 4;       |   |   |   |   |   |   |   | F | D | E  | S  |

ou si la branche n'est pas prise :

|              | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |
|--------------|---|---|---|---|---|---|---|---|---|----|
| a+= 1;       | F | D | E | S |   |   |   |   |   |    |
| a+= 2;       |   | F | D | E | S |   |   |   |   |    |
| if (a < 100) |   |   | F | D | E | S |   |   |   |    |
| a+= 3;       |   |   |   |   |   |   |   |   |   |    |
| a+= 4;       |   |   |   |   |   |   | F | D | E | S  |

On peut voir assez simplement que l'impact d'une branche sur le temps de traitement n'est pas n√©gligeable !
Heureusement, il existe une technique qui permet de r√©duire l'impact de la branche sur le nombre de cycles du CPU : la pr√©diction de branche.


Quand le CPU tombe sur une branche conditionnelle, il examine les probabilit√©s de prendre tel ou tel chemin (en fonction des cas d√©j√† rencontr√©).
Il va "consid√©rer" que cette branche est vraie et va continuer l'ex√©cution telle quelle.

Par exemple, si la branche est pr√©dite comme prise et l'est effectivement, l'ex√©cution ressemblerait √† :

|              | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|--------------|---|---|---|---|---|---|---|---|---|
| a+= 1;       | F | D | E | S |   |   |   |   |   |
| a+= 2;       |   | F | D | E | S |   |   |   |   |
| if (a < 100) |   |   | F | D | E | S |   |   |   |
| a+= 3;       |   |   |   | F | D |   | E | S |   |
| a+= 4;       |   |   |   |   | F | D |   | E | S |

On gagne deux cycles, soit ~19% (9/11) plus rapide que sans cette optimisation.

Si par contre, la branche est pr√©dite comme prise, mais le pr√©dicteur s'est tromp√©, il devra laisser tomber ce qu'il √©tait en train de faire et recommencer √† la bonne branche.

L'ex√©cution ressemble √† √ßa quand la pr√©diction est mauvaise :

|              | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |
|--------------|---|---|---|---|---|---|---|---|---|----|
| a+= 1;       | F | D | E | S |   |   |   |   |   |    |
| a+= 2;       |   | F | D | E | S |   |   |   |   |    |
| if (a < 100) |   |   | F | D | E | S |   |   |   |    |
| a+= 3;       |   |   |   | F | D |   |   |   |   |    |
| a+= 4;       |   |   |   |   |   |   | F | D | E | S  |

Quand le pr√©dicteur se trompe, on est plus lent que quand il a raison, mais le temps d'ex√©cution n'est pas plus mauvais que s'il n'y avait pas de pr√©dicteur du tout.

La pr√©diction de branche peut donc nous faire gagner quelques cycles... Est-ce n√©gligeable en pratique ou peut-on voir l'effet sur du vrai code en production ?

### Exemple

Un exemple assez connu viens de la question la [plus upvot√©e de Stack Overflow](https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array).

On part d'un tableau d'entier qui contient des nombres al√©atoire compris entre `[-1000; 1000]` et on √©crit un programme qui additionne tout les entiers positifs de ce tableau.

En Java, on pourrait √©crire le programme de cette mani√®re :
```java
    int[] array = IntStream.generate(() -> rnd.nextInt() % 1_000)
        .limit(30_000)
        .toArray();
    int[] sortedArray = IntStream.of(input).sorted().toArray();

    long sumPositive(int[] array) {
        long sum = 0;
        for (int value : array) {
          if (value >= 0) {
            sum += value;
          }
        }
        return sum;
    }
```


L'appel de la fonction `sumPositive` fait exactement le m√™me nombre de calculs qu'on lui passe le tableau tri√© ou non.
Cependant, la version tri√©e va environ 5 fois plus vite.

| Benchmark               | Score                       |
|-------------------------|-----------------------------|
| sortedArray             | 104995.716 ¬± 473.420  ops/s |
| unsortedArray           | 22568.343 ¬± 102.114  ops/s  |

On peut voir le m√™me effet en utilisant les APIs `java.util.Stream` :

```java
    private long sumStream(int[] array) {
      return Arrays.stream(array).filter(i -> i >= 0).sum();
    }
```

| Benchmark               | Score                       |
|-------------------------|-----------------------------|
| streamSortedArray       | 97041.833 ¬± 610.366  ops/s  |
| streamUnsortedArray     | 21495.011 ¬± 145.442  ops/s  |

La version "branchless" n'est pas impact√©e par le tri du tableau.

```java
    private long branchlessSumPositive(int[] array) {
      long sum = 0;
      for (int value : array) {
        sum += ~(value >> 31) & value;
      }
      return sum;
    }
```

| Benchmark               | Score                       |
|-------------------------|-----------------------------|
| branchlessSortedArray   | 70806.141 ¬± 260.635  ops/s  |
| branchlessUnsortedArray | 70930.320 ¬± 354.355  ops/s  |
